{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKwbnaD5xx7i",
        "outputId": "d1e75eb6-4e76-4b0c-dc45-9896e1d18eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzH-eSm1wwlH",
        "outputId": "c6b2e823-2b47-47d6-aab2-1ed0286b1ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import json\n",
        "from re import sub\n",
        "from pymystem3 import Mystem\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def txt2str(file_name):\n",
        "    with open(file_name, 'r', encoding='utf-8') as f:\n",
        "        txt = sub(r'[\\.,?\\-!:;\"*()]', '', f.read())\n",
        "    return txt[:2000]  # txt\n",
        "\n",
        "def str2txt(file_name, txt):\n",
        "    with open(file_name, 'w', encoding='utf-8') as f:\n",
        "        f.write(txt)\n",
        "\n",
        "def str2jsonl(file_name, analyzed_text):\n",
        "    out_lst = []\n",
        "    for word in analyzed_text:\n",
        "        out_lst.append({'lemma': word[0].normal_form,\n",
        "                        'word': word[0].word,\n",
        "                        'pos': word[0].tag.POS})\n",
        "    with open(f'{file_name}.jsonl', 'w', encoding='utf-8') as f:\n",
        "        json.dump(out_lst, f, ensure_ascii = False, indent = 4)\n",
        "\n",
        "\n",
        "def lemmit_2(text):\n",
        "    lemmatized_text = Mystem().lemmatize(text)\n",
        "    return lemmatized_text\n",
        "\n",
        "def lemmit(text):  # in case Mystem does not work\n",
        "    lemmatized_text = ' '.join((MorphAnalyzer().parse(morph))[0].normal_form for morph in text.split())\n",
        "    return lemmatized_text\n",
        "\n",
        "def tokenit(text):\n",
        "    tokenized_text = nltk.word_tokenize(text)\n",
        "    return tokenized_text\n",
        "\n",
        "def analyzit(text):\n",
        "    analyzed_text = [MorphAnalyzer().parse(word) for word in text]\n",
        "\n",
        "    return analyzed_text\n",
        "\n",
        "def pos_ratio(analyzed_text):\n",
        "    pos_list = [analyzed_word[0].tag.POS for analyzed_word in analyzed_text]\n",
        "    pos_ratio_dict = Counter(pos_list)\n",
        "    total_word = len(analyzed_text)\n",
        "    for key in pos_ratio_dict.keys():\n",
        "        pos_ratio_dict[key] = round(pos_ratio_dict[key] / total_word, 2)\n",
        "\n",
        "    return pos_ratio_dict\n",
        "\n",
        "def print_pos_ratio(pos_ratio_dict):\n",
        "    for key in pos_ratio_dict.keys():\n",
        "        print(f'{key}: {int(pos_ratio_dict[key] * 100)}%')\n",
        "\n",
        "def top20verbs(analyzed_text):\n",
        "    verbs = [analyzed_word[0].normal_form for analyzed_word in analyzed_text if analyzed_word[0].tag.POS == 'VERB']\n",
        "    top_verbs = Counter(verbs).most_common(20)\n",
        "    return top_verbs\n",
        "\n",
        "def top20adverbs(analyzed_text):\n",
        "    adverbs = [analyzed_word[0].normal_form for analyzed_word in analyzed_text if analyzed_word[0].tag.POS == 'ADVB']\n",
        "    top_adverbs = Counter(adverbs).most_common(20)\n",
        "    return top_adverbs\n",
        "\n",
        "def top25bigrams(lemmatized_text):\n",
        "    bigrams = nltk.bigrams(lemmatized_text)\n",
        "    top_bigrams = [('-'.join(big[0]), big[1])for big in Counter(bigrams).most_common(25)]\n",
        "    return top_bigrams\n",
        "\n",
        "def top25trigrams(lemmatized_text):\n",
        "    trigrams = nltk.trigrams(lemmatized_text)\n",
        "    top_trigrams = [('-'.join(big[0]), big[1])for big in Counter(trigrams).most_common(25)]\n",
        "    return top_trigrams\n",
        "\n",
        "def print_top(top_lst):\n",
        "    for top_tup in top_lst:\n",
        "        print(f'Total number of \"{top_tup[0]}\" in text: {top_tup[1]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf7nyjKIrFak"
      },
      "source": [
        "2. (2 points) Lemmatize the text using mystem (if you absolutely do not want to use mystem, you can use any other suitable tool we have discussed) and save the result into a .txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qNTn0kFQrjvz"
      },
      "outputs": [],
      "source": [
        "murakami = txt2str('text.txt')\n",
        "lemmatized_murakami = ''.join(lemmit(murakami))\n",
        "str2txt('lemmatized_text.txt', lemmatized_murakami)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT6z_60irLtB"
      },
      "source": [
        "3. (3 points)\n",
        "    \n",
        "    - tokenize the text using nltk\n",
        "    - analyze the words using pymorphy\n",
        "    - save the results of the analysis in jsonlines (.jsonl): every line contains morphological analysis in a form of a dictionary ```{\"lemma\": \"конь\", \"word\": \"коня\", \"pos\": \"NOUN\"}```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sX9moKL9rkcJ"
      },
      "outputs": [],
      "source": [
        "murakami = txt2str('text.txt')\n",
        "tokenized_murakami = tokenit(murakami)\n",
        "analyzed_murakami = analyzit(tokenized_murakami)\n",
        "str2jsonl('murakami', analyzed_murakami)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2jbBToCrdKd"
      },
      "source": [
        "4. (2 points) Answer the following questions:\n",
        "    \n",
        "    - What percentage constitutes each pos? (E.g., for the verb, the number of verbs divided by the total number of words)\n",
        "    - Print out top-20 verbs and adverbs\n",
        "    - you can keep the stop words or you can get rid of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhiZD8FDrlCc",
        "outputId": "f03027df-9aa3-425e-9f5c-959d96c07a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOUN: 25%\n",
            "NPRO: 7%\n",
            "VERB: 13%\n",
            "CONJ: 13%\n",
            "PREP: 12%\n",
            "ADJF: 8%\n",
            "ADJS: 2%\n",
            "PRCL: 7%\n",
            "PRTF: 0%\n",
            "ADVB: 10%\n",
            "GRND: 0%\n",
            "NUMR: 1%\n",
            "INTJ: 0%\n",
            "PRED: 1%\n",
            "INFN: 2%\n",
            "COMP: 0%\n",
            "\n",
            "Top verbs:\n",
            "Total number of \"говорить\" in text: 4\n",
            "Total number of \"быть\" in text: 3\n",
            "Total number of \"кивать\" in text: 2\n",
            "Total number of \"взять\" in text: 2\n",
            "Total number of \"заметить\" in text: 1\n",
            "Total number of \"стать\" in text: 1\n",
            "Total number of \"наклонить\" in text: 1\n",
            "Total number of \"понюхать\" in text: 1\n",
            "Total number of \"оказаться\" in text: 1\n",
            "Total number of \"решить\" in text: 1\n",
            "Total number of \"интересоваться\" in text: 1\n",
            "Total number of \"очнуться\" in text: 1\n",
            "Total number of \"отяжелеть\" in text: 1\n",
            "Total number of \"слушаться\" in text: 1\n",
            "Total number of \"пересчитывать\" in text: 1\n",
            "Total number of \"отвечать\" in text: 1\n",
            "Total number of \"обойтись\" in text: 1\n",
            "Total number of \"нибыть\" in text: 1\n",
            "Total number of \"идти\" in text: 1\n",
            "Total number of \"принести\" in text: 1\n",
            "\n",
            "Top adverbs:\n",
            "Total number of \"ещё\" in text: 3\n",
            "Total number of \"темно\" in text: 2\n",
            "Total number of \"немного\" in text: 2\n",
            "Total number of \"где\" in text: 2\n",
            "Total number of \"сколько\" in text: 2\n",
            "Total number of \"тогда\" in text: 2\n",
            "Total number of \"понятно\" in text: 1\n",
            "Total number of \"довольно\" in text: 1\n",
            "Total number of \"много\" in text: 1\n",
            "Total number of \"совсем\" in text: 1\n",
            "Total number of \"лениво\" in text: 1\n",
            "Total number of \"только\" in text: 1\n",
            "Total number of \"плоховато\" in text: 1\n",
            "Total number of \"всегда\" in text: 1\n",
            "Total number of \"снова\" in text: 1\n",
            "Total number of \"пока\" in text: 1\n",
            "Total number of \"насмешливо\" in text: 1\n",
            "Total number of \"откуда\" in text: 1\n",
            "Total number of \"иначе\" in text: 1\n",
            "Total number of \"здесь\" in text: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "murakami = txt2str('text.txt')\n",
        "tokenized_murakami = tokenit(murakami)\n",
        "analyzed_murakami = analyzit(tokenized_murakami)\n",
        "pos = pos_ratio(analyzed_murakami)\n",
        "print_pos_ratio(pos)\n",
        "print()\n",
        "\n",
        "print('Top verbs:')\n",
        "print_top(top20verbs(analyzed_murakami))\n",
        "print()\n",
        "\n",
        "print('Top adverbs:')\n",
        "print_top(top20adverbs(analyzed_murakami))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQj3T-8mrgXp"
      },
      "source": [
        "5. (1 point) Find top-25 bigrams and trigrams for your text (use nltk.bigrams), use only lemmas, get rid of the punctuation. Comment shortly on the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA7-2G0xrlnq",
        "outputId": "9b4a695b-3e0d-4ce2-95ee-0a19c12dfc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top bigrams:\n",
            "Total number of \"белый-майка\" in text: 2\n",
            "Total number of \"а-на\" in text: 2\n",
            "Total number of \"харуки-мураками\" in text: 2\n",
            "Total number of \"мураками-кафка\" in text: 2\n",
            "Total number of \"кафка-на\" in text: 2\n",
            "Total number of \"на-пляж\" in text: 2\n",
            "Total number of \"парень-по\" in text: 2\n",
            "Total number of \"по-прозвище\" in text: 2\n",
            "Total number of \"прозвище-ворона\" in text: 2\n",
            "Total number of \"у-ты\" in text: 2\n",
            "Total number of \"у-он\" in text: 2\n",
            "Total number of \"я-кивать\" in text: 2\n",
            "Total number of \"говорить-ворона\" in text: 2\n",
            "Total number of \"денежка-то\" in text: 2\n",
            "Total number of \"тогда-и\" in text: 2\n",
            "Total number of \"и-думать\" in text: 2\n",
            "Total number of \"думать-быть\" in text: 2\n",
            "Total number of \"аннотация-я\" in text: 1\n",
            "Total number of \"я-заметить\" in text: 1\n",
            "Total number of \"заметить-что\" in text: 1\n",
            "Total number of \"что-на\" in text: 1\n",
            "Total number of \"на-грудь\" in text: 1\n",
            "Total number of \"грудь-белый\" in text: 1\n",
            "Total number of \"майка-налиплый\" in text: 1\n",
            "Total number of \"налиплый-что\" in text: 1\n",
            "\n",
            "Top trigrams:\n",
            "Total number of \"харуки-мураками-кафка\" in text: 2\n",
            "Total number of \"мураками-кафка-на\" in text: 2\n",
            "Total number of \"кафка-на-пляж\" in text: 2\n",
            "Total number of \"парень-по-прозвище\" in text: 2\n",
            "Total number of \"по-прозвище-ворона\" in text: 2\n",
            "Total number of \"тогда-и-думать\" in text: 2\n",
            "Total number of \"и-думать-быть\" in text: 2\n",
            "Total number of \"аннотация-я-заметить\" in text: 1\n",
            "Total number of \"я-заметить-что\" in text: 1\n",
            "Total number of \"заметить-что-на\" in text: 1\n",
            "Total number of \"что-на-грудь\" in text: 1\n",
            "Total number of \"на-грудь-белый\" in text: 1\n",
            "Total number of \"грудь-белый-майка\" in text: 1\n",
            "Total number of \"белый-майка-налиплый\" in text: 1\n",
            "Total number of \"майка-налиплый-что\" in text: 1\n",
            "Total number of \"налиплый-что-то\" in text: 1\n",
            "Total number of \"что-то-чёрный\" in text: 1\n",
            "Total number of \"то-чёрный-по\" in text: 1\n",
            "Total number of \"чёрный-по-форма\" in text: 1\n",
            "Total number of \"по-форма-вроде\" in text: 1\n",
            "Total number of \"форма-вроде-большой\" in text: 1\n",
            "Total number of \"вроде-большой-бабочка\" in text: 1\n",
            "Total number of \"большой-бабочка-с\" in text: 1\n",
            "Total number of \"бабочка-с-раскрытый\" in text: 1\n",
            "Total number of \"с-раскрытый-крыло\" in text: 1\n"
          ]
        }
      ],
      "source": [
        "murakami = txt2str('text.txt')\n",
        "lemmatized_murakami = ''.join(lemmit(murakami))\n",
        "print('Top bigrams:')\n",
        "print_top(top25bigrams(lemmatized_murakami.split()))\n",
        "print()\n",
        "print('Top trigrams:')\n",
        "print_top(top25trigrams(lemmatized_murakami.split()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}